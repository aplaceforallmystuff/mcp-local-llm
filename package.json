{
  "name": "mcp-local-llm",
  "version": "1.0.1",
  "description": "MCP server for delegating mechanical tasks to local LLMs via Ollama",
  "type": "module",
  "main": "dist/index.js",
  "bin": {
    "mcp-local-llm": "./dist/index.js"
  },
  "scripts": {
    "build": "tsc",
    "start": "node dist/index.js",
    "dev": "tsc --watch"
  },
  "keywords": [
    "mcp",
    "llm",
    "ollama",
    "local-ai",
    "claude-code",
    "model-context-protocol"
  ],
  "author": "Jim Christian",
  "license": "MIT",
  "repository": {
    "type": "git",
    "url": "https://github.com/aplaceforallmystuff/mcp-local-llm"
  },
  "homepage": "https://jimchristian.net",
  "dependencies": {
    "@modelcontextprotocol/sdk": "^1.0.0",
    "openai": "^4.70.0"
  },
  "devDependencies": {
    "@types/node": "^22.0.0",
    "typescript": "^5.6.0"
  },
  "engines": {
    "node": ">=18.0.0"
  }
}
